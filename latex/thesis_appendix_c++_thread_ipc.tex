\hypertarget{c++_thread_ipc}{\chapter{C++: thread-ipc.cpp}}
\lstset{language=C++}
\begin{lstlisting}
//----------------------------------------------------------------------------
// LEGEND:
//   //% : comments added by us.
//   //# : a line that has not been modelled.
//   //! : a line that has been added by us.
//----------------------------------------------------------------------------

/** Receiver-ready callback.  
    Receivers make sure to call this function on waiting senders when
    they get ready to receive a message from that sender. Senders need
    to overwrite this interface.

    Class Thread's implementation wakes up the sender if it is still in
    sender-wait state.
 */
PUBLIC virtual
bool
Thread::ipc_receiver_ready(Receiver *recv)
{
  assert(receiver());                                                      //#
  assert(receiver() == recv);                                              //#
  assert(receiver() == current());                                         //#

  if(!(state() & Thread_ipc_in_progress))
    return false;

  if(!recv->sender_ok(this))
    return false;
  
  recv->ipc_init(this);

  state_add_dirty (Thread_ready | Thread_transfer_in_progress);

  ready_enqueue();                                                         //#

  // put receiver into sleep
  receiver()->state_del_dirty(Thread_ready);

  return true;
}

/** L4 IPC system call.
    This is the `normal'' version of the IPC system call.  It usually only
    gets called if ipc_short_cut() has failed.
    @param regs system-call arguments.
    @return value to be returned in %eax register.
 */
IMPLEMENT inline NOEXPORT ALWAYS_INLINE
void
Thread::sys_ipc()
{
  Sys_ipc_frame *regs = sys_frame_cast<Sys_ipc_frame>(this->regs());       //#

  Ipc_err ret(0);                                                          //# 
  L4_timeout t = regs->timeout();                                          //#

  // find the ipc partner thread belonging to the destination id
  L4_uid id              = regs->snd_dst();                                //#
  bool have_receive_part = regs->rcv_desc().has_receive();                 //#
  bool have_send_part    = regs->snd_desc().has_snd();                     //#
  bool have_sender       = false;                                          //#
  bool lookup_done       = false;                                          //#
  Thread *partner        = 0;                                              //#
  Sender *sender         = 0;                                              //#
  Irq_alloc *interrupt 	 = 0;                                              //#   
  
  // Add Thread_delayed_* flags if this a "next-period" IPC.
  // The flags must be cleared again on all exit paths from this function.
  if (EXPECT_FALSE (id.next_period()))                                     //#
    {
      state_add (Thread_delayed_deadline);                                 //#

      if (id.is_nil() && t.rcv_exp() && !t.rcv_man() &&                    //#
          !regs->has_abs_rcv_timeout())		// next period, 0 timeout  //#
        goto success;                                                      //#

      if (mode() & Nonstrict)                                              //#
        state_add (Thread_delayed_ipc);                                    //#
    }
  
  // do we do a closed receive operation?
  if (EXPECT_TRUE(have_receive_part))                                      //#
    {
      if (regs->rcv_desc().open_wait())                                    //#
	have_sender = true;                                                //#
      else if (EXPECT_FALSE(id.is_nil()))                                  //#
	{
          // only prepare IPC for timeout != 0                             //# 
          if (!t.rcv_exp() || t.rcv_man() || regs->has_abs_rcv_timeout())  //#
            {
              sender = nil_thread;                                         //#  
              have_sender = true;                                          //#
            }
        }
      else if (EXPECT_FALSE(id.is_irq()))                                  //#
	{	
          interrupt = Irq_alloc::lookup (regs->irq());                     //#

	  if (EXPECT_FALSE (!interrupt))                                   //#
	    {
	      commit_ipc_failure (regs, Ipc_err::Enot_existent);           //#
	      return;                                                      //#
	    }

	  if (interrupt->owner() != this)                                  //#
	    {
	      // a receive with a timeout != 0 from a non-associated
	      // interrupt is illegal
	      if (!t.rcv_exp() || t.rcv_man()                              //#
		  || regs->has_abs_rcv_timeout())                          //#
		{
		  commit_ipc_failure (regs, Ipc_err::Enot_existent);       //#
		  return;                                                  //#
		}
	    }

	  if (interrupt->owner() == this)                                  //#
	    {
	      // we always try to receive from the
	      // assoc'd irq first, not from the spec. one
	      sender = nonull_static_cast<Irq*>(interrupt);                //#
	      have_sender = true;                                          //#
	    }
	}
      else					// regular thread id       //#
        {
	  partner = lookup (id, space());                                  //#
	  lookup_done = true;                                              //#

          if (EXPECT_FALSE (!partner || partner->state() == Thread_invalid))//#
            {
              commit_ipc_failure (regs, Ipc_err::Enot_existent);           //#
              return;                                                      //#
            }

          if (EXPECT_FALSE (id.is_preemption()))                           //#
            sender = partner->preemption();                                //#
          else                                                             //#
            sender = partner;                                              //#

          have_sender = true;                                              //#
        }
    }

  if (EXPECT_TRUE(have_send_part))                                         //#
    {
      // irq quirks
      if (EXPECT_FALSE(id.is_irq()))                                       //#
	{
	  Irq_alloc *irq = Irq_alloc::lookup(regs->irq());                 //#
	  if (EXPECT_FALSE(!irq || irq->owner() != this))                  //#
	    {
	      // failed -- could not associate new irq
	      commit_ipc_failure (regs, Ipc_err::Enot_existent);           //#
	      return;                                                      //#
	    }

	  if (regs->msg_word(0) == 0) // ack IRQ                           //#
	    irq->acknowledge();                                            //#
	  else if (regs->msg_word(0) == 1) // disassociate IRQ             //#
	    disassociate_irq(irq);                                         //#
	  else                                                             //#
	    {
	      // failed -- could not associate new irq
	      commit_ipc_failure (regs, Ipc_err::Enot_existent);           //#
	      return;                                                      //#
	    }
	  have_send_part = false;                                          //#
	}
      else if (! lookup_done)                                              //#
	partner = lookup (id, space());                                    //#
    }
  
  if (EXPECT_FALSE(have_receive_part && !have_sender))                     //#
    {
      if (!interrupt) // is disassoc from IRQ                              //#
	{
	  assert(t.rcv_exp() && !t.rcv_man()); // timeout 0                //#
	  //
	  // disassociate from all IRQs 
	  //
	  if (_irq)                                                        //#
	    {
	      Irq_alloc::free_all(this);                                   //#
	      _irq = 0;                                                    //#
	    }
	  commit_ipc_failure (regs, Ipc_err::Retimeout);                   //#
	  return;                                                          //#
	}
      else                                                                 //#
	{
	  //
	  // associate with an interrupt
	  //
	  if (associate_irq(interrupt))                                    //#
	    {
	      // success
	      commit_ipc_failure (regs, Ipc_err::Retimeout);               //#
	      return;                                                      //#
	    }
	}
      have_receive_part = false;                                           //#
    }

  if (EXPECT_TRUE(have_send_part || have_receive_part))      
    ret = do_ipc(have_send_part, partner,
	         have_receive_part, sender,
	         t, regs);
  
success:                                                                   //#
  if (EXPECT_TRUE(!ret.has_error()))                                       //#
    commit_ipc_success (regs, ret);                                        //#
  else                                                                     //# 
    commit_ipc_failure (regs, ret);                                        //# 

  // New period doesn't begin as long as Thread_delayed_deadline is still set
  while (state_change_safely (~(Thread_delayed_deadline | Thread_ready),   //#
                                Thread_delayed_deadline))                  //#  
    schedule();                                                            //#
}

PRIVATE
Ipc_err Thread::do_send_wait (Thread *partner, L4_timeout t, Sys_ipc_frame *regs)
{

  // test if we have locked the partner 
  // in the best case the partner is unlocked
  assert(!partner->thread_lock()->test()                                   
  	 || partner->thread_lock()->lock_owner() == this);                 

  state_add_dirty(Thread_polling|Thread_send_in_progress|Thread_ipc_in_progress);
  // register partner so that we can be dequeued by kill()
  set_receiver (partner);                                                  //#

  // lock here for the preemption points
  partner->thread_lock()->lock_dirty();
  Proc::preemption_point();

  if(state() & Thread_cancel)
    {
      partner->thread_lock()->clear_dirty();

      state_del (Thread_ipc_sending_mask
                 |Thread_transfer_in_progress
                 |Thread_ipc_in_progress);

      return Ipc_err(Ipc_err::Secanceled);
    }
  
  if(partner->sender_ok(this))
    return 0;
  
  sender_enqueue (partner->sender_list(), sched_context()->prio());

  assert(partner->partner() != this);                                      //!
  assert(!(state() & Thread_transfer_in_progress));                        //!

  Proc::preemption_point();

  IPC_timeout timeout;                                                     //#
  
  if (EXPECT_FALSE(t.snd_exp()))
    {
      Unsigned64 tval = snd_timeout (t, regs);                             //#
      // Zero timeout or timeout expired already -- give up
      if (tval == 0)                                                       //#
	  return abort_send(Ipc_err::Setimeout, partner);
      
      // enqueue timeout
      Proc::preemption_point();                                            //# 
      
      set_timeout (&timeout);                                              //#
      timeout.set (tval);                                                  //#
    }

  do
    {

      partner->thread_lock()->clear_dirty();
      // possible PREEMPTION POINT

      Proc::preemption_point();

      //% We have not modelled the call to the <schedule()> function as
      //% its purpose is to give the receiver time to become ready to
      //% receive a message from this thread. In our model this can
      //% happen when the <preemption_point()> function is called.
      //% As we do not actually model the time a receiver needs to
      //% have to become ready this waiting is uncessary.
      if((state() & (Thread_ipc_in_progress | Thread_polling               //#
		     | Thread_cancel | Thread_transfer_in_progress))       //#
	 == (Thread_ipc_in_progress|Thread_polling))                       //#
	{
	  state_del_dirty(Thread_ready);                                   //#
	  schedule();                                                      //#
	}

      //% This preemption point is superfluous in our model as we 
      //% abstracted away the code directly above and thus would end
      //% up with two consecutive preemption points.
      Proc::preemption_point();                                            //#

      // if we are here 5 cases are  possible
      // - timeout has hit
      // - ipc was canceled
      // - the receiver had awoken us
      // - the receiver has been killed
      // - or someone has simply awake us, then we go to sleep again

      partner->thread_lock()->lock_dirty();
      
      if (EXPECT_FALSE(state() & Thread_cancel))
	break;

      // ipc handshake bit is set
      if(state() & Thread_transfer_in_progress)
	break;

      assert(!partner->in_ipc(this));

      //% This assertion is redundant due to the break specified above.
      assert(!(state() & Thread_transfer_in_progress));

      // detect if we have timed out
      if (timeout.has_hit())
	{
	  // ipc timeout always clear this flag
	  assert(!(state() & Thread_ipc_in_progress));
	  return abort_send(Ipc_err::Setimeout, partner);
	}

      if(partner->state() == Thread_dead)
	return abort_send(Ipc_err::Enot_existent, partner);

      // huh? someone has simply awake us, goto sleep again

      // Make sure we're really still in IPC
      assert(state() &  Thread_ipc_in_progress);                           

      // adding again, so that ipc_receiver_ready find the correct state
      state_add_dirty(Thread_polling);                                     

    } while(true);                                                         //#
  
  // because the handshake has already taken place
  // an triggered timeout can be ignored
  if (timeout.has_hit())
    state_add_dirty(Thread_ipc_in_progress);
 
  // reset is only an simple dequeing operation from an double
  // linked list, so we dont need an extra preemption point for this
  timeout.reset();                                                         //#
  set_timeout(0);                                                          //#
  
  Proc::preemption_point();
  sender_dequeue (partner->sender_list());
  Proc::preemption_point();

  state_del_dirty(Thread_polling);

  if (EXPECT_FALSE(state() & Thread_cancel))
    {
      // this test catch partner-cancel and kill
      if(!partner->in_ipc(this))
	return abort_send(Ipc_err::Secanceled, partner);
      
      // the partner still waits for us, cancel them too
      partner->state_change(~Thread_ipc_in_progress,
			    Thread_cancel | Thread_ready);
      partner->ready_enqueue();                                            //#
      Proc::preemption_point();                                            //#
      return abort_send(Ipc_err::Seaborted, partner);
    }

  // partner canceled?, handles kill too
  if(EXPECT_FALSE(!partner->in_ipc(this))) 
    return abort_send(Ipc_err::Seaborted, partner);

  if(partner->state() == Thread_dead)
    return abort_send(Ipc_err::Enot_existent, partner);

  assert(state() & Thread_ipc_in_progress);
  assert (!in_sender_list());

  return 0;
}

PRIVATE
Ipc_err Thread::abort_send(Ipc_err err, Receiver *partner)
{
  state_del_dirty (Thread_send_in_progress | Thread_polling | 
                   Thread_ipc_in_progress | Thread_transfer_in_progress);

  assert(partner);                                                         //#

  Proc::preemption_point();
  if(in_sender_list())
    sender_dequeue (partner->sender_list());

  Proc::preemption_point();
  partner->thread_lock()->clear_dirty();

  //% Another preemption point is not useful in our model as after this
  //% function has been called the termination will be terminated and
  //% thus no other statements will be executed which might have been
  //% influenced by the preemption point.
  Proc::preemption_point();
  if (_timeout && _timeout->is_set())                                      //#
    _timeout->reset();                                                     //#

  set_timeout(0);                                                          //#
	  
  return err;
}

PRIVATE inline NEEDS["logdefs.h"]
Ipc_err Thread::try_handshake_receiver(Thread *partner, L4_timeout t, 
                                       Sys_ipc_frame *regs)
{

  // By touching the partner tcb we can raise an pagefault.
  // The Pf handler might be enable the interrupts, if no mapping in
  // the master kernel directory exists.
  // Because the partner can created in between,
  // and partner->state() == Thread_invalid is insufficient
  // we need a cancel test.
  //

  if(EXPECT_FALSE (partner == 0
		   // must not send to L4_NIL_ID
		   || partner->state() == Thread_invalid
		   || partner == nil_thread))
    return Ipc_err (Ipc_err::Enot_existent);

  assert(cpu_lock.test());                                                 //#
      
  if(EXPECT_FALSE(partner->thread_lock()->test())) // lock is not free
    {
      Proc::preemption_point();
      partner->thread_lock()->lock_dirty();
    }

  if(EXPECT_FALSE(state() & Thread_cancel))
    {
      // clear_dirty() handle the not locked case too
      partner->thread_lock()->clear_dirty();
      return Ipc_err(Ipc_err::Secanceled);
    }

  Ipc_err err(0);
  
  if (EXPECT_FALSE (!partner->sender_ok
		    (nonull_static_cast<Sender*>(current_thread()))))
  
    {
      err = do_send_wait(partner, t, regs);

      // if an error occured, we should not hold the lock anymore
      assert(!err.has_error() || partner->thread_lock()->lock_owner() != this);
    }

  return err;
}

PRIVATE inline
void
Thread::wake_receiver (Thread *receiver)
{
  // If neither IPC partner is delayed, just update the receiver's state
  if (EXPECT_TRUE (!((state() | receiver->state()) & Thread_delayed_ipc))) //#
    {
      receiver->state_change_dirty(~(Thread_ipc_receiving_mask
				    | Thread_ipc_in_progress),
				  Thread_ready);
      return;
    }

  //% As we do not model periodic threads, we assume that the
  //% if-statement above will always be true. The section below is thus
  //% completely ignored.

  // Critical section if either IPC partner is delayed until its next period
  assert(cpu_lock.test());                                                 //#
  
  // Sender has no receive phase and deadline timeout already hit
  if ( (state() & (Thread_receiving |                                      //#
		   Thread_delayed_deadline | Thread_delayed_ipc)) ==       //#
      Thread_delayed_ipc)                                                  //#
    {
      state_change_dirty (~Thread_delayed_ipc, 0);                         //#
      switch_sched (sched_context()->next());                              //#
      _deadline_timeout.set (Timer::system_clock() + period());            //#
    }

  // Receiver's deadline timeout already hit
  if ( (receiver->state() & (Thread_delayed_deadline |                     //#
                             Thread_delayed_ipc) ==                        //#
	                     Thread_delayed_ipc))                          //#
    {
      receiver->state_change_dirty (~Thread_delayed_ipc, 0);               //#
      receiver->switch_sched (receiver->sched_context()->next());          //#
      receiver->_deadline_timeout.set (Timer::system_clock() +             //#
                                       receiver->period());                //# 
    }

  receiver->state_change_dirty (~(Thread_ipc_mask|Thread_delayed_ipc),     //#
				Thread_ready);                             //#
}


/**
 * Send an IPC message.
 *        Block until we can send the message or the timeout hits.
 * @param partner the receiver of our message
 * @param t a timeout specifier
 * @param regs sender's IPC registers
 * @return sender's IPC error code
 */
PRIVATE
Ipc_err Thread::do_ipc (bool have_send, Thread *partner,
			bool have_receive, Sender *sender,
			L4_timeout t, Sys_ipc_frame *regs)
{

  bool dont_switch = false;                                                //#
  
  if(have_send)
    {
      Ipc_err err = try_handshake_receiver(partner, t, regs);
     
      if(EXPECT_FALSE(err.has_error()))
	return err;

      assert(!(state() & Thread_polling));                                 

      partner->ipc_init(this);      

      // mmh, we can reset the receivers timeout
      // ping pong with timeouts will profit from it, because
      // it will require much less sorting overhead
      // if we dont reset the timeout, the possibility is very high
      // that the receiver timeout is in the timeout queue
      if (partner->_timeout && partner->_timeout->is_set())                //#
	{
	  partner->_timeout->reset();                                      //#
	  partner->set_timeout(0);                                         //#
	}

      Ipc_err ret = transfer_msg(partner, regs);

      if (Config::deceit_bit_disables_switch &&                            //#
          regs->snd_desc().deceite())                                      //#
	dont_switch = true;                                                //#

      // partner locked, i.e. lazy locking (not locked) or we own the lock
      assert(!partner->thread_lock()->test()                               
	     || partner->thread_lock()->lock_owner() == this);             


      if(EXPECT_FALSE(ret.has_error() || !have_receive))
	{
	  // make the ipc partner ready if still engaged in ipc with us
	  if(partner->in_ipc(this))
	    {
	      wake_receiver(partner);
	      if(!dont_switch)                                             //# 
  partner->thread_lock()->set_switch_hint(SWITCH_ACTIVATE_LOCKEE);//#
	    }

	  partner->thread_lock()->clear_dirty();

	  state_del (Thread_ipc_sending_mask
		     |Thread_transfer_in_progress
		     |Thread_ipc_in_progress);
	  
	  return ret;
	}

      partner->thread_lock()->clear_dirty_dont_switch();
      // possible preemption point

      if(EXPECT_TRUE(!partner->in_ipc(this)))
        {
	  state_del (Thread_ipc_sending_mask
		     |Thread_transfer_in_progress
		     |Thread_ipc_in_progress);
	
	  return Ipc_err::Secanceled;
        }

      wake_receiver(partner);

    }
  else
    regs->msg_dope(0);                                                   //#

  assert(have_receive);
  if (state() & Thread_cancel)                                           //#
    {
      state_del(Thread_ipc_mask);                                        //#
      return Ipc_err::Recanceled;                                        //#
    }

  //% The lines below can be found in our model in a slightly altered version,
  //% namely in the becoming
  prepare_receive_dirty (sender, regs);

  while (EXPECT_TRUE
         ((state() & (Thread_receiving | Thread_ipc_in_progress | Thread_cancel))
          == (Thread_receiving | Thread_ipc_in_progress)) ) 
    {
    
      Sender *next = 0;                                                    //#

      if(EXPECT_FALSE((long)*sender_list()))                               //#
	{

	  if(sender) // closed wait                                        //#
	    {
	      
	      if(sender->in_sender_list()                                  //#
		 && this == sender->receiver()                             //#
		 && sender->ipc_receiver_ready(this))                      //#
		next = sender;                                             //#
	    }
	  else // open wait                                                //#
	    {
	      
	      next = *sender_list();                                       //#
	      if(!next->ipc_receiver_ready(this))                          //#
		{
		  next->sender_dequeue_head(sender_list());                //#
		  Proc::preemption_point();                                //#
		  continue;                                                //#
		}
	    }
	}
      
      assert(cpu_lock.test());                                             //#
    
      //% We will skip the following conditional statement as it only
      //% deals with the scheduling of the partner and we have not
      //% modelled scheduling.
      if(EXPECT_FALSE((long) next))                                        //#
	{
	  
	  assert(!(state() & Thread_ipc_in_progress)                       //#
		 || !(state() & Thread_ready));                            //#
	  
	  // maybe switch_exec should return an bool to avoid testing the 
	  // state twice
	  if(have_send) {                                                  //#
	    
	    assert(partner);                                               //#
	    assert(partner->sched());                                      //#
	  }

	  if(EXPECT_TRUE(have_send && !dont_switch                         //#
			 && (partner->state() & Thread_ready)              //#
			 && (next->sender_prio() <= partner->sched()->prio())))//#
	      switch_exec_locked(partner,  Context::Not_Helping);          //#
	  else                                                             //#
	    {
	      Proc::preemption_point();                                    //#
              assert(cpu_lock.test());                                     //#
	      if(have_send && (partner->state() & Thread_ready))           //#
		partner->ready_enqueue();                                  //#
	      schedule();                                                  //#
	    }
	  
	  assert(state() & Thread_ready);                                  //#
	}

      else if(EXPECT_TRUE(have_send && (partner->state() & Thread_ready)))
        {
          if(!dont_switch)                                                 //#
    	    switch_exec_locked(partner,  Context::Not_Helping);            //#
          else                                                             //#
            partner->ready_enqueue();                                      //#
        }
      else                                                                 //#
	goto_sleep(t, regs);                                               //#
      
      have_send = false;                                                   //#
    }
  
  assert(!(state() & Thread_ipc_sending_mask));                            //#

  if (EXPECT_FALSE((long)_timeout)) {                                      //#
    _timeout->reset();                                                     //#
    set_timeout(0);                                                        //#
  }

  // if the receive operation was canceled/finished before we 
  // switched to the old receiver, finish the send
  if(have_send && (partner->state() & Thread_ready))                       //#
    {
      if(!dont_switch)                                                     //#
        switch_exec_locked(partner,  Context::Not_Helping);                //#
      else                                                                 //#
        partner->ready_enqueue();                                          //#  
    }

  // fast out if ipc is already finished
  if(EXPECT_TRUE((state() &                                                //#
                  (~(Thread_fpu_owner|Thread_cancel))) == Thread_ready))   //#
    return  get_ipc_err (regs);

  //% We will never reach this point as we do not model long IPC, we 
  //% therefore assume that the if-statement directly above this 
  //% statement is always true.
  handle_long_ipc();                                                       //#

  // abnormal termination?
  if (EXPECT_FALSE (state() & Thread_ipc_receiving_mask))                  //#
    {
      // the IPC has not been finished.  could be timeout or cancel
      // XXX should only modify the error-code part of the status code

      if (state() & Thread_busy)        // we've presumably been reset!    //#
        commit_ipc_success (regs, Ipc_err::Reaborted);                     //#

      //else 
      if (state() & Thread_cancel)      // we've presumably been reset!    //#
        {
#if 0                                                                      //#
          if (state() & Thread_transfer_in_progress)                       //#
	    {
	  LOG_MSG(this,"REAB2");                                           //# 
            commit_ipc_success (regs, Ipc_err::Reaborted);                 //#
	    }
          else                                                             //#
	    {
	  LOG_MSG(this,"RECA1");                                           //#
#endif                                                                     //# 
            commit_ipc_success (regs, Ipc_err::Recanceled);                //#
#if 0                                                                      //#
	    }
#endif                                                                     //#
        }

      else                                                                 //#
        commit_ipc_success (regs, Ipc_err::Retimeout);                     //#
    }

  state_del (Thread_ipc_mask);                                             //#

  return get_ipc_err (regs);            // sender puts return code here    //#
}

PRIVATE inline NEEDS ["map_util.h", Thread::copy_utcb_to, 
		      Thread::unlock_receiver]
Ipc_err Thread::transfer_msg (Thread *receiver,
                              Sys_ipc_frame *sender_regs)
{
  //% In our model, we assume that the transferring of a message always 
  //% succeeds so all lines in this function have been abstracted away
  //% in our model.
  
  if (!Config::deceit_bit_disables_switch && sender_regs->snd_desc().deceite())//#
    panic ("deceiving ipc");    // XXX unimplemented                       //#

  Sys_ipc_frame* dst_regs = receiver->rcv_regs();                          //#
  const L4_msgdope ret_dope(sender_regs->snd_desc(),                       //#
      Sys_ipc_frame::num_reg_words(), 0);                                  //#


  dst_regs->msg_dope (ret_dope);        // status code: rcv'd 2 dw         //#

  // copy message register contents
  sender_regs->copy_msg (dst_regs);                                        //# 

  copy_utcb_to (receiver);                                                 //#

  // copy sender ID
  dst_regs->rcv_src (id());                                                //#

  // fast out if only register msg
  if(EXPECT_TRUE(sender_regs->snd_desc().is_register_ipc()))               //#   
      return 0;

  //% We will never reach this point as we do not model long IPC and thus
  //% assume that <is_register_ipc()> always returns true.

  // because we do a longer ipc with preemption points, we set a corrent ipc state
  state_add_dirty(Thread_send_in_progress |                                //#
                  Thread_ipc_in_progress| Thread_transfer_in_progress);    //#

  Mword ret = 0;                                // status code: IPC successful
  // we need the lock here definitly
  receiver->thread_lock()->lock_dirty();                                   //#

  // short flexpage mapping to register/rmap receiver
  if(EXPECT_TRUE (sender_regs->snd_desc().msg() == 0                       //#
                  && (dst_regs->rcv_desc().is_register_ipc()               //#
                      || dst_regs->rcv_desc().rmap())))                    //#
    {
      assert(sender_regs->snd_desc().map());                               //#

      if (EXPECT_FALSE (! dst_regs->rcv_desc().rmap()) )                   //#
        // rcvr not expecting an fpage?                                    //# 
        {
          dst_regs->msg_dope_set_error(Ipc_err::Remsgcut);                 //#
          ret = Ipc_err::Semsgcut;                                         //#
        }
      else                                                                 //#
        {
          Proc::sti();                                                     //#

          dst_regs->msg_dope_combine                                       //#
            (fpage_map(space(),                                            //#
                       L4_fpage(sender_regs->msg_word(1)),                 //#
                       receiver->space(), dst_regs->rcv_desc().fpage(),    //#
                       sender_regs->msg_word(0),                           //#
                       L4_fpage(sender_regs->msg_word(1)).grant()));       //#

          Proc::cli();                                                     //#

          if (dst_regs->msg_dope().rcv_map_failed())                       //#
            ret = Ipc_err::Semapfailed;                                    //#
        }
      return ret;                                                          //#
    }

  Proc::preemption_point();                                                //#

  // else long ipc
  prepare_long_ipc(receiver, sender_regs);                                 //#

  Ipc_err error_ret;                                                       //#

  assert(state() & Thread_send_in_progress);                               //#
  receiver->thread_lock()->clear_dirty();                                  //#

  CNT_IPC_LONG;                                                            //#
  Proc::sti();                                                             //#
  error_ret = do_send_long (receiver, sender_regs);                        //#
  Proc::cli();                                                             //#

  assert(receiver->thread_lock()->lock_owner() == this);                   //#

  assert(error_ret.has_error() || state()                                  //#
         & (Thread_send_in_progress | Thread_transfer_in_progress));       //#

  return error_ret;                                                        //#
}
\end{lstlisting}