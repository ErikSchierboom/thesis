\hypertarget{conclusions}{\chapter{Conclusions and future work}}

\begin{epigraphs}
\qitem{``If you don't fail at least 90 percent of the time, you're not aiming high enough.''}{Alan Kay}
\end{epigraphs}

\section{Conclusions}
For extremely critical programs (such as the software of the space shuttle), relatively small programs or algorithms (such as an encryption algorithm), the effort to apply full verification might be worthwhile. Unfortunately, for most other programs full verification is not a valid option because it requires too much effort. One of the reasons why full verification often requires so much time is the inability to automatically convert from source code to the proof system's language. This conversion is often necessary as most programs are written in languages that do not support proof creation. The only alternative to automated conversion is manual conversion, which requires (far) more effort than automated conversion. A manual conversion has the advantage though that it actively involves the converter in the conversion process, which is likely to lead to a better understanding of the system.\emptyline

An alternative to full verification is partial verification, in which only certain parts of the code are verified. The main benefit of this approach is that it can use a more compact model. In order to create a compact model, one abstracts away parts that are not relevant to the properties one wants to prove. The danger of applying abstractions is that the model might not accurately reflect the source code, parts may have been abstracted away incorrectly. Another possible pitfall is that the model has become too abstract, which might prevent lower-level bugs from being found. Besides all these disadvantages, this approach also has its benefits. Its main benefit is its use of a more compact model, which likely results in smaller and simpler proofs. Furthermore, one does not need to know all the implementation details of parts that have been abstracted away, a functional description of these parts often suffices.\emptyline

In our research, we created a model of a subsystem of the Fiasco microkernel, namely IPC. Even though the subsystem is relatively small, it was still quite complex due to its many inter-relations with other parts of the kernel. We therefore decided to create an abstract model of Fiasco IPC. Of all abstractions made, the most important were the preemption points, which are the points in the IPC path where execution might be (temporarily) switched to another thread. Using our abstract model, we tried to verify three different properties. The first property ensured that after sending an IPC message, there should not be any thread lock on the receiver. Our second property ensured that in a combined send and receive IPC call, the receiver is ready to send a message back to the sender when it is required to do so. These two properties were verified without requiring any additional assumptions. Both verified properties ensured that in certain situations, threads would not be waiting infinitely, which is obviously important to a real-time system. The third property, in which we verified the various assertions in the IPC path, proved more troublesome. In the end, for one assertion we had to resort to using an axiom. We believe our inability to verify this property was due to our simplified modeling of preemption points. Our second problem was with another assertion, which required an additional assumption about the initial state. Even with this assumption we failed to verify the assertion, which turned out to be due to an error in the source code.\emptyline

We were thus able to find a bug in the Fiasco IPC implementation, even with our greatly abstracted model. The bug we found was not likely to occur, but when it did it would have crashed the whole kernel and therefore everything running on top of it. The bug finding thus had a direct, practical use in that the Fiasco kernel had one bug removed from its code. Although useful, we consider the fact that our abstract model was able to find the bug more important. It shows that it is not necessary to create a strict, one-on-one conversion of the source code to find bugs. This opens up the possiblity for verification on larger programs, where one only focuses on those aspects of particular interest for verification and abstracts away the rest.\emptyline

When one attempts to create an abstract model, choosing those abstractions wisely is a key step that requires a lot of insight into the inner workings of the system. We recommend that everything that is not abstracted away is converted as faithful to the code as possible, as this greatly increases the confidence one has in the correctness of the model. This is important as proofs of a model are only useful insofar one trusts the model to be a correct representation of the source code.

\section{Future work}
As has become clear in this thesis, there are still many open problems and points of improvement. In this section we will discuss the most important.

\subsection{Further verification}
As we have only verified three properties of IPC in Fiasco, there are many other properties open for verification. It might be more interesting though to verify our three properties in an expanded version of our model to see if they can still be proven. Every abstraction applied is a candidate for expansion, however we consider preemption points the most interesting candidate for expanding upon for the following reason. As preemption points form an integral part of IPC, they should preferrably be modelled as faithful to the source code as possible. Conversely, in our model preemption points are the most abstracted component. As preemption points themselves depend on other abstractions, such as the complete abstraction of scheduling and the abstraction of the receive part (corresponding to a receiver becoming ready). Therefore an expansion of preemption points in the model would most likely also include integration respectively expansion of these abstractions into the model.\emptyline

Not only is inclusion of scheduling a required condition for more accurate preemption point modeling, it is also a very important aspect of Fiasco (IPC) itself. Modeling scheduling is therefore not only necessary for a better preemption point model, but it also opens up several other possible verification properties and improves the model's similarity to the source code. An interesting scheduling-related property would be verifying the absence of priority inversion in IPC.\emptyline

If scheduling gets included into the model and preemption points get a more faithful representation, it makes sense to move the receive part functionality from the preemption points back to its original location. A receiver becoming ready can now be modelled by actually scheduling the receiver and following its IPC path. Having done this, it would be interesting to check if the sender being equal to the receiver once again leads to problematic proofs.\emptyline

Another important aspect of Fiasco IPC that has been abstracted is the long IPC path. Not only does inclusion of the long IPC path make the path itself longer, and thus proofs larger, it also greatly increases the complexity of proofs dealing with the IPC path. This is in most part due to the full preemptability of the long IPC path. In the short IPC path, there are only specific points in which execution could be interrupted (namely the preemption points), but execution in the long IPC path can be interrupted after every instruction. For proofs, this leads to an enormous increase in the state space needed to be examined, as after every executed statement a number of branches is introduced that is equal to all possible actions a preemption might result in (of which there are many). The main problem is thus how to deal with this preemptability (and resulting state space explosion) efficiently in proofs.\emptyline

As we have seen, there are many abstractions that can be expanded upon in future work. However, there is one open issue with the current proofs that certainly deserves looking into: our inability to verify the assertion stating that, at a certain point, the sender and receiver must not be engaged in IPC with each other. We believe that this property could not be proven due to our simplified version of a receiver becoming ready and possibly some additional assumptions might be necessary. If this simplified version is expanded upon, as we just discussed, it is interesting to see if our suspicions were correct or if there is a flaw in our model.

\subsection{Modular proofs}
Currently, one of the problems with proofs is their fragility: a small modification in the model often requires whole proofs to be redone. A possible solution to this problem is to create a more modular model, where a small modification results in only some or parts of the proof having to be redone. In our research, we successfully created a very modular model where small changes only required small changes in the proofs. To create a more modular model, we split some large functions into smaller functions, whilst retaining the original semantics. Although more modular proofs can thus in part be achieved in the current situation, certain aspects of the proof (particularly instantiations of lemmas) are often still bound to a specific model and are thus still susceptive to small changes in that model. For proofs to become less fragile, it is important that these fragile aspects of proofs can be handled better.

\subsection{Automation of verification}
Often even relatively basic proofs need some form of user-guidance. When a larger proof is being constructed, the amount of work involved becomes very high. For verification to become more successful it is therefore essential that as much as possible of the proof construction can be automated. This is particularly important for larger programs to be verified, but it is also important for quick verification of smaller programs or models.

\subsection{Improved conversion}
As said, the conversion from program to theorem prover is currently of vital importance to the verification of programs. To be able to apply full verification to larger programs, the conversion to a theorem prover should be done (almost) fully automated, as manual conversion can be very time-intensive. Although there are some converters available at the moment, most only support a subset of the features of the source language. For (much) wider applicability to real-life applications, it is important that all features of a language are supported. As an example, the LOOP tool \cite{vandenberg01loop} (which converts Java to PVS or Isabelle) currently does not support the concept of threads. This is a clear limitation, especially when one considers that future applications will focus more and more on multi-threading because of the advent of multi-processor systems.